{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. py:currentmodule:: emat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emat\n",
    "emat.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ema_workbench\n",
    "import os, numpy, pandas, functools\n",
    "from emat.util.xmle import Show\n",
    "from emat.viz.scatter import scatter_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = emat.util.loggers.log_to_stderr(20, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Exploratory Scope"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "The model scope is defined in a YAML file.  For this Road Test example, the scope file is named \n",
    ":ref:`road_test.yaml <road_test_scope_file>` and is included in the model/tests directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_test_scope_file = emat.package_file('model','tests','road_test.yaml')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "The filename for the YAML file is the first argument when creating a :class:`Scope`\n",
    "object, which will load and process the content of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_scope = emat.Scope(road_test_scope_file)\n",
    "road_scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A short summary of the scope can be reviewed using the `info` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_scope.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, more detailed information about each part of the scope can be\n",
    "accessed in four list attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_scope.get_constants()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_scope.get_uncertainties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_scope.get_levers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_scope.get_measures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Database\n",
    "\n",
    "The exploratory modeling process will typically generate many different sets of outputs,\n",
    "for different explored modeling scopes, or for different applications.  It is convenient\n",
    "to organize these outputs in a database structure, so they are stored consistently and \n",
    "readily available for subsequent analysis.\n",
    "\n",
    "The `SQLiteDB` object will create a database to store results.  When instantiated with\n",
    "no arguments, the database is initialized in-memory, which will not store anything to\n",
    "disk (which is convenient for this example, but in practice you will generally want to\n",
    "store data to disk so that it can persist after this Python session ends)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emat_db = emat.SQLiteDB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An EMAT Scope can be stored in the database, to provide needed information about what the \n",
    "various inputs and outputs represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_scope.store_scope(emat_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to store another scope with the same name (or the same scope) raises a KeyError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    road_scope.store_scope(emat_db)\n",
    "except KeyError as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can review the names of scopes already stored in the database using the `read_scope_names` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emat_db.read_scope_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Design\n",
    "\n",
    "Actually running the model can be done by the user on an *ad hoc* basis (i.e., manually defining every \n",
    "combination of inputs that will be evaluated) but the real power of EMAT comes from runnning the model\n",
    "using algorithm-created experimental designs.\n",
    "\n",
    "An important experimental design used in exploratory modeling is the Latin Hypercube.  This design selects\n",
    "a random set of experiments across multiple input dimensions, to ensure \"good\" coverage of the \n",
    "multi-dimensional modeling space.\n",
    "\n",
    "The `design_latin_hypercube` function creates such a design based on a `Scope`, and optionally\n",
    "stores the design of experiments in a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emat.experiment.experimental_design import design_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design = design_experiments(road_scope, db=emat_db, n_samples_per_factor=10, sampler='lhs')\n",
    "design.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_design = design_experiments(road_scope, db=emat_db, n_samples=5000, sampler='lhs', design_name='lhs_large')\n",
    "large_design.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can review what experimental designs have already been stored in the database using the \n",
    "`read_design_names` method of the `Database` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emat_db.read_design_names('EMAT Road Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Model in Python"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Up until this point, we have been considering a model in the abstract, defining in the :class:`Scope` what the inputs \n",
    "and outputs will be, and designing some experiments we would like to run with the model.  Now we will actually \n",
    "interface with the model itself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition\n",
    "\n",
    "In the simplest approach for EMAT, a model can be defined as a basic Python function, which accepts all\n",
    "inputs (exogenous uncertainties, policy levers, and externally defined constants) as named keyword\n",
    "arguments, and returns a dictionary where the dictionary keys are names of performace measures, and \n",
    "the mapped values are the computed values for those performance measures.  The `Road_Capacity_Investment`\n",
    "function provided in EMAT is an example of such a function.  This made-up example considers the \n",
    "investment in capacity expansion for a single roadway link.  The inputs to this function are described\n",
    "above in the Scope, including uncertain parameters in the volume-delay function,\n",
    "traffic volumes, value of travel time savings, unit construction costs, and interest rates, and policy levers including the \n",
    "amount of capacity expansion and amortization period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emat.model.core_python import PythonCoreModel\n",
    "from emat.model.core_python import Road_Capacity_Investment"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "The :class:`PythonCoreModel <emat.model.core_python.core_python_api.PythonCoreModel>` object \n",
    "provides an interface that links the basic Python function that represents \n",
    "the model, the :class:`Scope <emat.scope.scope.Scope>`, and optionally the \n",
    ":class:`Database <emat.database.database.Database>` used to manage data storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emat.model.core_python import PythonCoreModel\n",
    "m = PythonCoreModel(Road_Capacity_Investment, scope=road_scope, db=emat_db)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "From the :class:`PythonCoreModel`, which links the model, scope, design, and database, we can run the design of experiments.  \n",
    "This will systematically run the core model with each set of input parameters in the design, store the results in\n",
    "the database, and return a pandas.DataFrame containing the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import SequentialEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SequentialEvaluator(m) as eval_seq:\n",
    "    lhs_results = m.run_experiments(design_name='lhs', evaluator=eval_seq)\n",
    "lhs_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with SequentialEvaluator(m) as eval_seq:\n",
    "#     lhs_large_results = m.run_experiments(design_name='lhs_large', evaluator=eval_seq)\n",
    "# lhs_large_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a particular design has been run once, the results can be recovered from the database without re-running the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_results = m.read_experiments(design_name='lhs')\n",
    "reload_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to load only the parameters, or only the performance meausures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhs_params = m.read_experiment_parameters(design_name='lhs')\n",
    "lhs_params.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhs_outcomes = m.read_experiment_measures(design_name='lhs')\n",
    "lhs_outcomes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART\n",
    "\n",
    "Classification and Regression Trees (CART) can also be used for scenario discovery. \n",
    "They partition the explored space (i.e., the scope) into a number of sections, with each partition\n",
    "being added in such a way as to maximize the difference between observations on each \n",
    "side of the newly added partition divider, subject to some constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ema_workbench.analysis import cart\n",
    "\n",
    "# cart_alg = cart.CART(\n",
    "#     m.read_experiment_parameters(design_name='lhs_large'), \n",
    "#     m.read_experiment_measures(design_name='lhs_large')['net_benefits']>0,\n",
    "# )\n",
    "# cart_alg.build_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show(cart_alg.show_tree(format='svg')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cart_alg.boxes_to_dataframe(include_stats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emat import Constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The common use case for constraints in robust optimation is imposing requirements\n",
    "on solution outcomes. For example, we may want to limit our robust search only\n",
    "to solutions where the expected present cost of the capacity expansion is less\n",
    "than some particular value (in our example here, 4000).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_1 = Constraint(\n",
    "    \"Maximum build_travel_time\", \n",
    "    outcome_names=\"build_travel_time\",\n",
    "    function=Constraint.must_be_less_than(70),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our second constraint is based exclusively on an input: the capacity expansion\n",
    "must be at least 10.  We could also achieve this kind of constraint by changing\n",
    "the exploratory scope, but we don't necessarily want to change the scope to \n",
    "conduct a single robust optimization analysis with a constraint on a policy lever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_2 = Constraint(\n",
    "    \"Minimum Capacity Expansion\", \n",
    "    parameter_names=\"expand_capacity\",\n",
    "    function=Constraint.must_be_greater_than(20),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to impose constraints based on a combination of inputs and outputs.\n",
    "For example, suppose that the total funds available for pay-as-you-go financing are\n",
    "only 1500.  We may thus want to restrict the robust search to only solutions that\n",
    "are almost certainly within the available funds at 99% confidence (a model output) but only \n",
    "if the Paygo financing option is used (a model input).  This kind of constraint can\n",
    "be created by giving both `parameter_names` and `outcomes_names`, and writing a constraint\n",
    "function that takes two arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_3 = Constraint(\n",
    "    \"Maximum Paygo Present Cost\", \n",
    "    parameter_names='debt_type',\n",
    "    outcome_names='present_cost_expansion',\n",
    "    function=lambda i,j: max(0, j-4000) if i=='Paygo' else 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints=[\n",
    "            constraint_1,\n",
    "            constraint_2,\n",
    "            constraint_3,\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emat.util.constraints import batch_contraint_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_contraint_check(constraints, lhs_params, lhs_outcomes, False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emat.scope.box import Bounds, Box, Boxes, find_all_boxes_with_parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = emat_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    s = Box(scope=road_scope)\n",
    "except TypeError:\n",
    "    print(\"correct error\")\n",
    "else:\n",
    "    raise RuntimeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Box(\n",
    "    name=\"Speedy\", \n",
    "    scope=road_scope,\n",
    "    upper_bounds={'build_travel_time':70},\n",
    "    relevant=['net_benefits', 'time_savings'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = Box(\n",
    "    name=\"Notable\", \n",
    "    scope=road_scope, \n",
    "    parent=\"Speedy\",\n",
    "    lower_bounds={'expand_capacity': 20},\n",
    "    relevant=road_scope.get_lever_names(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = Box(\n",
    "    name=\"No Tax Dollars\",\n",
    "    scope=road_scope, \n",
    "    parent=\"Notable\",\n",
    "    allowed={\n",
    "        'debt_type': {'Paygo', 'Rev Bond'},\n",
    "        'interest_rate_lock': {False},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = Boxes(s,s2,s3, scope=road_scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.fancy_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.get_chain(\"No Tax Dollars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(u.get_chain(\"No Tax Dollars\").chain_repr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.write_boxes(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uu = db.read_boxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uu.fancy_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uu.get_chain(\"No Tax Dollars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.read_scope('EMAT Road Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emat.interactive import Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore = Explorer('db')\n",
    "explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emat.interactive import prototype_logging\n",
    "prototype_logging.handler.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prototype_logging.logger.setLevel(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True in {0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
