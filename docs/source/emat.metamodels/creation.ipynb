{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. py:currentmodule:: emat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emat\n",
    "from emat.util.loggers import timing_log\n",
    "emat.versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demostrate the creation of a meta-model, we will use the Road Test example model\n",
    "included with TMIP-EMAT.  We will first create and run a design of experiments, to\n",
    "have some experimental data to define the meta-model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emat.examples\n",
    "scope, db, model = emat.examples.road_test()\n",
    "design = model.design_experiments(design_name='lhs')\n",
    "results = model.run_experiments(design)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then create a meta-model automatically from these experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emat.model import create_metamodel\n",
    "\n",
    "with timing_log(\"create metamodel\"):\n",
    "    mm = create_metamodel(scope, results, suppress_converge_warnings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using the default meta-model regressor, as we are doing here, \n",
    "you can directly access a cross-validation method that uses the experimental\n",
    "data to evaluate the quality of the regression model.  The `cross_val_scores`\n",
    "provides a measure of how well the meta-model predicts the experimental \n",
    "outcomes, similar to an $R^2$ measure on a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timing_log(\"crossvalidate metamodel\"):\n",
    "    display(mm.cross_val_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply the meta-model directly on a new design of experiments, and \n",
    "use the `contrast_experiments` visualization tool to review how well the\n",
    "meta-model is replicating the underlying model's results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design2 = mm.design_experiments(design_name='lhs_meta', n_samples=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timing_log(\"apply metamodel\"):\n",
    "    results2 = mm.run_experiments(design2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emat.analysis import contrast_experiments\n",
    "contrast_experiments(mm.scope, results2, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Metamodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be desirable in some cases to construct a *partial* metamodel, covering only a subset of the performance measures.  This is likely to be particularly desirable if a large number of performance measures are included in the scope, but only a few are of particular interest for a given analysis. The time required for generating and using meta-models is linear in the number of performance measures included, so if you have 100 performance measures but you are only presently interested in 5, your meta-model can be created much faster if you only include the 5 performance measures.  It will also run much faster, but the run time for metamodels is so small anyhow, it's likely you won't notice.\n",
    "\n",
    "To create a partial meta-model for a curated set of performance measures, you can use the `include_measures` argument of the `create_metamodel` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timing_log(\"create limited metamodel\"):\n",
    "    mm2 = create_metamodel(\n",
    "        scope, results, \n",
    "        include_measures=['time_savings', 'present_cost_expansion'],\n",
    "        suppress_converge_warnings=True,\n",
    "    )\n",
    "\n",
    "with timing_log(\"crossvalidate limited metamodel\"):\n",
    "    display(mm2.cross_val_scores())\n",
    "\n",
    "with timing_log(\"apply limited metamodel\"):\n",
    "    results2_limited = mm2.run_experiments(design2)\n",
    "    \n",
    "results2_limited.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also an `exclude_measures` argument for the `create_metamodel` command, which will retain all of the scoped performance measures *except* the enumerated list.  This can be handy for dropping a few measures that are not working well, either because the data is bad in some way or if the measure isn't well fitted using the metamodel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timing_log(\"create limited metamodel\"):\n",
    "    mm3 = create_metamodel(\n",
    "        scope, results, \n",
    "        exclude_measures=['net_benefits'],\n",
    "        suppress_converge_warnings=True,\n",
    "    )\n",
    "\n",
    "with timing_log(\"crossvalidate limited metamodel\"):\n",
    "    display(mm3.cross_val_scores())\n",
    "\n",
    "with timing_log(\"apply limited metamodel\"):\n",
    "    results3_limited = mm3.run_experiments(design2)\n",
    "    \n",
    "results3_limited.info()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
